#!/usr/bin/python
#coding = utf8
import collections
import numpy
import random
from scipy.stats import mode
from matplotlib import pyplot

#28 attributes:
attr_info = [['surgery','nominal'],
			['age','nominal'],
			['hospital_number','nominal'],
			['rectal_temperature','numeric'],
			['pulse','numeric'],
			['respiratory_rate','numeric'],
			['temperature_of_extremities','nominal'],
			['peripheral_pulse','nominal'],
			['mucous_membranes','nominal'],
			['capillary_refill_time','nominal'],
			['pain','nominal'],
			['peristalsis','nominal'],
			['abdominal_distension','nominal'],
			['nasogastric_tube','nominal'],
			['nasogastric_reflux','nominal'],
			['nasogastric_reflux_PH','numeric'],
			['rectal_examination','nominal'],
			['abdomen','nominal'],
			['packed_cell_volume','numeric'],
			['total_protein','numeric'],
			['abdominocentesis_appearance','nominal'],
			['abdomcentesis_total_protein','numeric'],
			['outcome','nominal'],
			['surgical_lesion','nominal'],
			['type_of_lesion_1','nominal'],
			['type_of_lesion_2','nominal'],
			['type_of_lesion_3','nominal'],
			['cp_data_list','nominal']]

def data_distance(line1, line2):
	vector1 = [x for x in line1 if x != '?' && line2[line1.index(x)] != '?']
	vector2 = [x for x in line2 if x != '?' && line1[line2.index(x)] != '?']
	sqDiffVector = vector1-vector2  
    sqDiffVector=sqDiffVector**2  
    sqDistances = sqDiffVector.sum()  
    distance = sqDistances**0.5  
    return distance  


def data_quarter(attr_list):
	attr_len = len(attr_list)
	return [attr_list[attr_len/4], attr_list[attr_len*3/4]] 

def data_cov(line1,line2):
	data = numpy.array(line1,line2)
	#计算两组数的相关系数
	#返回结果为矩阵，第i行第j列的数据表示第i组数与第j组数的相关系数。对角线为1
	return numpy.corrcoef(data)

def list2str(sample_list):
	sample_str = str(sample_list)
	sample_str = max_frequency_str.replace('[','')
	sample_str = max_frequency_str.replace(']','') + '\n'
	sample_str = max_frequency_str.replace(',',' ')
	return sample_str



def data_preprocessing(case_name, attr_list, horse_colic_list):
	if case_name == 'erase':
		pass
	
	else if case_name == 'max_frequency':
		max_frequency_attr_list = []
		max_frequency_file = open('/media/gs/study/gushuang/data/DataMining/horse-colic/max_frequency_horse-colic.data','w')
		
		for attr in range(len(attr_info)):
			temp_list = attr_list[attr]
			earse_attr_list = [x for x in temp_list if x != '?']
			attr_replace = mode(earse_attr_list)
			temp_list = [attr_replace if x=='?' else x for x in temp_list]
			max_frequency_attr_list.append(temp_list)
		max_frequency_horse_colic_list = numpy.transpose(max_frequency_attr_list)
		for item in max_frequency_horse_colic_list:
			max_frequency_str = list2str(item)
			max_frequency_file.write(max_frequency_str)
		max_frequency_file.close()
	
	else if case_name == 'hotdeck':
		hotdeck_file = open('/media/gs/study/gushuang/data/DataMining/horse-colic/hotdeck_horse-colic.data','w')
		
		corrcoef_matrix = []
		corrcoef_list = []
		attr_map = []
		each_attr_map = []

		hotdeck_list = []
		hotdeck_attr_list = []

		uncompleted_data_list = []
		uncompleted_data_index_list = []


		random_list = random.sample(completed_data_index,2)
		corrcoef_matrix = data_cov(horse_colic_list[random_list[0]],horse_colic_list[random_list[1]])

		
		for n in range(28):
			corrcoef_list = corrcoef_matrix[n]
			del corrcoef_list[n]
			attr_map.append(sorted(enumerate(corrcoef_list),key = lambda x:x[1]))
		
		for i in range(len(horse_colic_lines)):
			hotdeck_list.append(horse_colic_list[i])
			if '?' not in hotdeck_list[i]:
				continue
			else:
				uncompleted_data_index_list = [x for x in range(28) if hotdeck_list[i][x] == '?']
				for uncomplete_index in uncompleted_data_index_list:
				each_attr_map = attr_map[uncomplete_index]
				for m in each_attr_map:
					if hotdeck_list[i][m[0]] == '?':
						continue;
					else:
						corr_attr = m[0]
						break;
				corr_line = attr_list.index(min(attr_list[corr_attr]-hotdeck_list[i][corr_attr]))
				corr_list = horse_colic_list[corr_line]
				hotdeck_list[i][uncomplete_index] = corr_list[uncomplete_index]
			hotdeck_str = list2str(hotdeck[i])
			hotdeck_file.write(hotdeck_str)
		hotdeck_file.close()
		hotdeck_attr_list = numpy.transpose(hotdeck_list)


	else if case_name == 'k-means':
		k_means_file = open('/media/gs/study/gushuang/data/DataMining/horse-colic/k_means_horse-colic.data','w')
		attr_distance = [[0 for i in range(len(horse_colic_lines))] for j in range(len(horse_colic_lines))]
		for i in range(len(horse_colic_lines)):
			for j in range(len(horse_colic_lines)):
				if i == j:
					attr_distance[i][j] = INF

				if attr_distance[j][i] != 0:
					attr_distance[i][j] = attr_distance[j][i]
				else:
					temp_list1 = horse_colic_list[i]
					temp_list2 = horse_colic_list[j]
					attr_distance[i][j] = attr_distance(temp_list1, temp_list2)
		# find k minimun distance
		sorted_distance = []
		minimun_k_distance = []
		minimun_k_list = []
		k_means_attr_list = []
		for i in range(len(horse_colic_lines)):
			k_means_list = horse_colic_list[i]
			sorted_distance = attr_distance[i]
			sorted(enumerate(sorted_distance),key = lambda x:x[1])
			for attr in range(len(attr_info)):
				attr_replace = 0
				attr_replace_count = 0
				if k_means_list[attr] == '?':
					for k in 10:
						minimun_k_index = sorted_distance[k][0]
						minimun_k_list = horse_colic_lines[minimun_k_index].spilt(' ')
						if minimun_k_list[attr] == '?':
							continue
						else:
							attr_replace_count = attr_replace_count + 1
							attr_replace = attr_replace + minimun_k_list[attr]/sorted_distance[k][1]
					k_means_list[attr] = attr_replace/attr_replace_count
				else:
					continue
			k_means_attr_list.append(k_means_list)
			k_means_str = list2str(k_means_list)
			k_means_file.write(k_means_str)
		k_means_file.close()
		k_means_attr_list = numpy.transpose(k_means_attr_list)

	else:
		return 'error'

#data abstract-----1-nominal attr frequency/2-numeric attr max & min & mean & middle & 1/4 & missing
def data_abstract(casename,each_attr_list, attr_flag, num):
	if attr_flag == 'nominal':
		each_attr_set = set(each_attr_list)
		for item in each_attr_set:
			hosre_colic_abstract[num].append({item: each_attr_list.count(item)})
		print hosre_colic_abstract[num]

	else if attr_flag == 'numeric':
		#[missing, max, min, mean, middle, 1/4, 3/4]
		missing_data = each_attr_list.count('?')
		hosre_colic_abstract[num].append(missing_data)
		hosre_colic_abstract[num].append(max(each_attr_list))
		hosre_colic_abstract[num].append(min(each_attr_list))
		hosre_colic_abstract[num].append(numpy.mean(each_attr_list))
		hosre_colic_abstract[num].append(numpy.median(each_attr_list))
		attr_quarter = data_quarter(each_attr_list)
		hosre_colic_abstract[num].append(attr_quarter[0])
		hosre_colic_abstract[num].append(attr_quarter[1])

		pyplot.hist(each_attr_list, 100)
     	pyplot.show()

     	pyplot.boxplot(each_attr_list, labels=['1'])
     	pyplot.show()

	else:
		
		print "error"



#read horse-colic data
horse_colic_file = open('/media/gs/study/gushuang/data/DataMining/horse-colic/horse-colic.data')
try:
	horse_colic_lines = horse_colic_file.readlines()
	horse_colic_list = []
	attr_list = [0] * len(attr_info)
	
	completed_data_index = []
	uncompleted_data_index = []
	for_counter = 0

	for line in horse_colic_lines:
		temp_list = line.spilt(' ')
		horse_colic_list.append(temp_list)

		for n in range(len(attr_info)):
			attr_list[n].append(temp_list[n])

		#method 3
		if '?' in horse_colic_list:
			completed_data_index.append(for_counter)
		else:
			uncompleted_data_index.append(for_counter)
		for_counter = for_counter + 1

except Exception as e:
	print "horse-colic.data file open failed!"
finally:
	horse_colic_file.close()

#data preprocessing---4 cases 'erase' 'max_frequency' 'hotdeck' 'k-means'

casename = 'erase'
data_preprocessing(casename, attr_list, horse_colic_list)


hosre_colic_abstract = []
for n in range(len(attr_info)):
	if casename == 'erase':
		each_attr_list = [x for x in attr_list[n] if x != '?']
	else if casename == 'max_frequency':
		each_attr_list = max_frequency_attr_list[n]
	else if casename == 'hotdeck':
		each_attr_list = hotdeck_attr_list[n]
	else if casename == 'k-means':
		each_attr_list = k_means_attr_list[n]
	else:
		print 'error'
	data_abstract(each_attr_list,attr_info[n][1],n)
	# plot
